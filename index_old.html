<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <!-- mobile-friendly scaling -->
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>RL4Med-DDPO</title>

    <!-- Bootstrap 5 CSS (responsive grid, utilities, ScrollSpy) -->
    <link
      href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css"
      rel="stylesheet"
    />
    <link
      href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap"
      rel="stylesheet"
    />
    <link
      href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css"
      rel="stylesheet"
    />
    <link rel="stylesheet" href="style.css" />
  </head>
  <body
    data-bs-spy="scroll"
    data-bs-target="#toc"
    data-bs-smooth-scroll="true"
    tabindex="0"
    id="top"
  >
    <!-- ================= NAVBAR ================= -->
    <nav class="navbar navbar-expand-lg sticky-top custom-navbar">
      <div class="container justify-content-center">
        <button
          class="navbar-toggler"
          type="button"
          data-bs-toggle="collapse"
          data-bs-target="#navbarNav"
          aria-controls="navbarNav"
          aria-expanded="false"
          aria-label="Toggle navigation"
        >
          <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarNav">
          <ul class="navbar-nav mx-auto d-flex justify-content-center gap-4">
            <li class="nav-item">
              <a class="nav-link text-center" href="#abstract">
                <i class="fas fa-book-open"></i>
                <span class="d-block mt-1">Abstract</span>
              </a>
            </li>
            <li class="nav-item">
              <a class="nav-link text-center" href="#method">
                <i class="fas fa-cogs"></i>
                <span class="d-block mt-1">Method</span>
              </a>
            </li>
            <li class="nav-item">
              <a class="nav-link text-center" href="#results">
                <i class="fas fa-chart-bar"></i>
                <span class="d-block mt-1">Results</span>
              </a>
            </li>
            <li class="nav-item">
              <a class="nav-link text-center" href="#conclusion">
                <i class="fas fa-lightbulb"></i>
                <span class="d-block mt-1">Conclusion</span>
              </a>
            </li>
            <li class="nav-item">
              <a class="nav-link text-center" href="#bibtex">
                <i class="fas fa-quote-right"></i>
                <span class="d-block mt-1">Citation</span>
              </a>
            </li>
          </ul>
        </div>
      </div>
    </nav>

    <!-- ================= HEADER ================= -->
    <header class="custom-header w-100 fade-in">
      <div class="container">
        <h1 class="h3 fw-semibold">
          HDLM: Unifying Autoregressive and Diffusion-Based Sequence Generation
        </h1>

        <div class="row justify-content-center my-3">
          <div class="col-md-3 text-center">
            <strong><a
                href="https://nimafathi.github.io/"
                target="_blank"
                rel="noopener noreferrer"
                class="author-link"
                >Nima Fathi</a
              ></strong><br />
            <small class="text-white-50"
              >Mila - Quebec AI Institute, <br> ServiceNow Research</small
            >
          </div>
          <div class="col-md-3 text-center">
            <strong
              ><a
                href="https://www.servicenow.com/research/author/pierre-andre-noel.html" 
                target="_blank"
                rel="noopener noreferrer"
                class="author-link"
                >Pierre-André Noël</a
              ></strong
            ><br />
            <small class="text-white-50"
              >ServiceNow Research</small
            >
          </div>
          <div class="col-md-3 text-center">
            <strong><a
                href="https://tscholak.github.io/"
                target="_blank"
                rel="noopener noreferrer"
                class="author-link"
                >Torsten Scholak</a
              ></strong><br />
            <small class="text-white-50"
              >ServiceNow Research</small
            >
          </div>
        </div>
        <p class="workshop-name">COLM 2025</p>
        
        <!-- Button group for better organization -->
        <div class="button-group">
          <!-- arXiv button -->
          <a
            class="custom-btn"
            href="https://arxiv.org/abs/2504.06416"
            target="_blank"
            rel="noopener noreferrer"
          >
            <img
              src="images/huggingface_logo-noborder.svg"
              width="20"
              height="20"
              class="me-2"
              alt="Hugging Face Logo"
            />
            arXiv
          </a>
          <!-- Hugging Face Weights button -->
          <a
            class="custom-btn"
            href="https://huggingface.co/your-username/your-model-repo"
            target="_blank"
            rel="noopener noreferrer"
          >
            <img
              src="images/arxiv-icon.svg"
              width="20"
              height="20"
              class="me-2"
              alt="arXiv Logo"
            />
            HDLM
          </a>
          <!-- GitHub button -->
          <a
            class="custom-btn"
            href="https://github.com/servicenow/hdlm"
            target="_blank"
            rel="noopener noreferrer"
          >
            <svg width="20" height="20" class="me-2" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg">
              <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.300 24 12c0-6.627-5.373-12-12-12z"/>
            </svg>
            Code
          </a>
          <a
            class="custom-btn"
            href="https://nimafathi.github.io/blog/2025/unifying-ar-diffusion/"
            target="_blank"
            rel="noopener noreferrer"
          >
            <svg width="20" height="20" class="me-2" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
              <path d="M7.5 2.25H16.5C17.7426 2.25 18.75 3.25736 18.75 4.5V19.5C18.75 20.7426 17.7426 21.75 16.5 21.75H7.5C6.25736 21.75 5.25 20.7426 5.25 19.5V4.5C5.25 3.25736 6.25736 2.25 7.5 2.25Z" stroke="currentColor" stroke-width="1.5"/>
              <path d="M9 8.25H15M9 11.25H15M9 14.25H12" stroke="currentColor" stroke-width="1.5" stroke-linecap="round"/>
            </svg>
            Blog
          </a>
        </div>
        <div class="company-attribution">
          <img src="images/ServiceNow-Logo-2022_400x200.png" alt="ServiceNow" class="servicenow-logo">
        </div>
      </div>
    </header>
    <div class="container-lg my-4">
        <!-- ================= TEASER ================= -->
        <figure class="text-center fade-in">
          <div class="d-inline-block w-50 text-start">
            <!-- Add text-start here -->
            <img
              src="images/figure1.png"
              alt="Paper teaser figure"
              class="img-fluid rounded"
            />
            <figcaption class="text-muted small mt-2">
              Figure 1: Comparison of synthetic samples generated from Stable Diffusion (left image) and Stable Diffusion 
              with Reinforcement Learning (right image). The text prompt for these image samples was - <code>A dermatoscopic 
                image with melanoma showing hairs</code>. Note the unwanted but relevant <span style="color: red;">artifacts</span> that do not align with the input text prompt.
            </figcaption>
          </div>
        </figure>

      <!-- ================= BODY LAYOUT ============ -->
      <div class="row gx-5 mt-4 justify-content-center">
        <!-- -------- Main article -------- -->
        <main class="col-lg-8 mx-auto">
          <section id="abstract" class="mb-5">
            <h2>Abstract</h2>
            <p>
              We present significant extensions to diffusion-based sequence generation models, blurring the line with autoregressive language models.
              We introduce hyperschedules, which assign distinct noise schedules to individual token positions, generalizing both autoregressive models (e.g., GPT) and conventional diffusion models (e.g., SEDD, MDLM) as special cases. 
              Second, we propose two hybrid token-wise noising processes that interpolate between absorbing and uniform processes, enabling the model to fix past mistakes, and we introduce a novel inference algorithm that leverages this new feature in a simplified context inspired from MDLM.
              To support efficient training and inference, we design attention masks compatible with KV-caching.
            Our methods achieve state-of-the-art perplexity and generate diverse, high-quality sequences across standard benchmarks, suggesting a promising path for autoregressive diffusion-based sequence generation.
            </p>
          </section>


          <section id="method" class="my-5">
            <h2>Method</h2>
          
            <!-- Key Contributions Box -->
            <div class="key-contributions-box p-4 rounded shadow-sm bg-light">
              <h3>Key Contributions</h3>
              <ul>
                <li>We introduce <strong>RL4Med-DDPO</strong>, the first framework to integrate policy optimization with vision-language foundation models for improved text-guided medical image synthesis using Stable Diffusion.</li>
                <li>We show that reinforcement learning (via DDPO) enhances the alignment between medical text prompts and the generated images, addressing common issues of semantic mismatch and spurious artifacts.</li>
                <li>We propose a new evaluation metric, <em>Artifact Prevalence Rate (APR)</em>, to quantify the presence of desired attributes and artifacts in synthesized images.</li>
                <li>Extensive experiments on the public ISIC2019 skin lesion dataset demonstrate that our method generates photorealistic images with improved text-image alignment, supporting more robust and bias-aware medical image synthesis.</li>
              </ul>
            </div>
          
            <!-- Architecture Figure -->
            <figure class="text-start mt-4">
              <img
                src="images/figure2.png"
                alt="Overview of RL4Med-DDPO pipeline"
                class="img-fluid rounded shadow-sm"
              />
              <figcaption class="text-muted small mt-2">
                Figure 2: Proposed architecture for policy optimization using a reward function for diverse 
                and realistic image generation using fine-tuned Stable Diffusion. Given an input text prompt, 
                the model synthesizes a realistic image x<sub>g</sub> during the reverse diffusion. This generated image 
                is then passed to a pre-trained classifier to compute the reward which helps guide the denoising 
                UNet to improve image synthesis so it is better semantically aligned with the input text.
              </figcaption>
            </figure>
          </section>

          <section id="results" class="my-5 text-start">
            <h2 class="text-start">Results</h2>
            
            <!-- Figure 1 -->
            <figure class="text-start mt-4">
              <img
                src="images/figure3.png"
                alt="Disentanglement property of Stable Diffusion"
                class="img-fluid rounded shadow-sm"
              />
              <figcaption class="text-muted small mt-2">
                Figure 3: Comparing real samples for the category "melanocytic nevus with gel bubbles" with the synthesized 
                images using fine-tuned Stable Diffusion (SD) and fine-tuned Stable Diffusion with reinforcement learning 
                (SD+RL). Note  the unwanted <span style="color:red;">artifacts</span> present in the image synthesized by SD.
              </figcaption>
            </figure>
          
            <!-- Figure 2 -->
            <figure class="text-start mt-4">
              <img
                src="images/figure4.png"
                alt="t-SNE plot of generated latent vectors"
                class="img-fluid rounded shadow-sm"
              />
              <figcaption class="text-muted small mt-2">
                Figure 4: Qualitative comparisons of synthesized images of subgroups (based on combinations 
                of disease and artifacts) for which none or a few (less than 20) real samples are present. 
                Note that some of these subgroups include combinations of attributes, such as melanoma with gel 
                bubbles and ink or melanocytic nevus with ink and hair.
              </figcaption>
            </figure>
          </section>

          <section id="conclusion" class="mb-5">
            <h2>Conclusion</h2>
            <p>
              In this work, we demonstrate the first method showing alignment between the text prompt 
              and image generation using a vision-foundation model guided by a policy optimization 
              for medical imaging applications. We show through extensive qualitative and quantitative 
              validation that these images align well with the input text prompt, and they are helpful 
              for downstream tasks such as augmenting the classifier to improve performance over minority classes. 
              Future work will explore the use of diverse policies for complex tasks such as subgroup clustering in 
              the latent space for disease image marker discovery.
            </p>
          </section>

          <section id="bibtex" class="mb-5">
            <h2>BibTeX</h2>
            <pre class="bg-light p-3 rounded border">
              @article{fathi2025unifying,
              title={Unifying autoregressive and diffusion-based sequence generation},
              author={Fathi, Nima and Scholak, Torsten and No{\"e}l, Pierre-Andr{\'e}},
              journal={arXiv preprint arXiv:2504.06416},
              year={2025}
            }
            </pre
            >
          </section>
        </main>
      </div>
      <!-- /row -->
    </div>
    <!-- /container -->

    <footer class="custom-footer">
      <div class="footer-box">
         © Nima Fathi | 2nd Conference on Language Modeling (COLM2025)
      </div>
    </footer>

    <!-- Bootstrap JS bundle (scrollspy, collapse, etc.) -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js"></script>

    <script>
      document.addEventListener("DOMContentLoaded", function () {
        const sections = document.querySelectorAll("section");

        const observer = new IntersectionObserver(
          (entries) => {
            entries.forEach((entry) => {
              if (entry.isIntersecting) {
                entry.target.classList.add("visible");
              } else {
                entry.target.classList.remove("visible");
              }
            });
          },
          {
            threshold: 0.1,
          },
        );

        sections.forEach((section) => {
          observer.observe(section);
        });
      });
    </script>

    <script>
      document.addEventListener("DOMContentLoaded", function () {
        const navbarHeight = document.querySelector(".custom-navbar").offsetHeight;
    
        // Add click event listener to all nav links
        document.querySelectorAll(".nav-link").forEach((link) => {
          link.addEventListener("click", function (event) {
            event.preventDefault(); // Prevent default anchor behavior
    
            const targetId = this.getAttribute("href").substring(1); // Get the target section ID
            const targetElement = document.getElementById(targetId);
    
            if (targetElement) {
              const offsetTop = targetElement.offsetTop - navbarHeight; // Adjust for navbar height
              window.scrollTo({
                top: offsetTop,
                behavior: "smooth", // Smooth scrolling
              });
            }
          });
        });
      });
    </script>
  </body>
</html>